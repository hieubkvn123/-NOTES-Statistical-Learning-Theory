\newpage
\subsection{Rademacher Complexity of ramp loss - two layers case}
\subsubsection{Problem Statement}
\textbf{Problem} : Consider the multi-class classification problem with $K \ge 2$ labels. Given a tuple of matrices $(M^{(1)}, M^{(2)})$ (that represents initialized weight matrices). Define the following class of tuples of weight matrices:

\begin{align*}
    \mathcal{A} = \biggCurl{
        \bigRound{
            A^{(1)}, A^{(2)}
        } : \|A^{(i)}\|_\sigma \le s_i, \ \| (A^{(i)} - M^{(i)})^T \|_{2, 1} \le a_i, \ \| A^{(2)} - M^{(2)} \|_F \le a_*
    }
\end{align*}

\noindent Where $a_i, s_i, R > 0$, $x\in \R^{d_0}, A^{(1)}\in\R^{d_1\times d_0}, A^{(2)}\in \R^{d_2\times d_1}$ ($d_2=K$). $\|.\|_\sigma$ denotes the spectral norm and $\|.\|_{p, q}$ denotes the matrix $(p, q)$ norm defined as:
\begin{align*}
    \|A\|_{p, q} = \biggRound{\sum_j\biggRound{\sum_{i}|A_{ij}|^p}^{q/p}}^{1/q}
\end{align*}    

\noindent Define the following class of two-layer neural networks:
\begin{align*}
    \F_\mathcal{A} = \bigCurl{
        x\mapsto A^{(2)}\sigma(A^{(1)}x) : \bigRound{A^{(1)}, A^{(2)}}\in\mathcal{A}, \ \sigma \text{ is } \rho\text{-Lipchitz w.r.t } l^2\text{-norm}, \ \|x\|_2 \le 1
    }
\end{align*}

\noindent Derive the Rademacher Complexity bound for the class of loss functions:
\begin{align*}
    \mathcal{L}_r = \biggCurl{
        (x, y) \mapsto l_r\bigRound{
            F_\vecbf{A}(x)_y - \max_{k\ne y}F_\vecbf{A}(x)_k
        } \Bigg| F_\vecbf{A} \in \F_\mathcal{A}
    }
\end{align*}

\noindent Where $l_r$ is the ramp loss with margin $r\in(0,1)$.

\noindent \color{red}
From this point on, we will refer to $\|.\|_p$ as the $l^p$ norm and the $\|.\|_p^S$ as the norm of a function $f$ defined over a sample $S$. Specifically:
\begin{align*}
    \|f\|_p^S = \biggRound{
        \frac{1}{|S|}\sum_{x_i \in S} f(x_i) ^p
    }^{1/p}
\end{align*}
\color{black}

\subsubsection{Solution}

\textbf{1. Bounding the covering number for $\mathcal{L}_r$} : Let $L_\vecbf{A} \in \mathcal{L}_r$ parameterized by $\vecbf{A}\in\mathcal{A}$ be defined as:
\begin{align*}
    L_\vecbf{A}(x, y) = l_r\bigRound{
        F_\vecbf{A}(x)_y - \max_{k\ne y} F_\vecbf{A}(x)_k
    }
\end{align*}

\noindent Then let $S=\bigCurl{(x_i, y_i)}_{i=1}^n$ be a sample dataset, for $L_\vecbf{A}, L_\vecbf{\bar A}\in\mathcal{L}_r$ and $(x_i, y_i)\in S$, we have:
\begin{align*}
    \bigAbs{L_\vecbf{A}(x_i, y_i) - L_\vecbf{\bar A}(x_i, y_i)} &= \bigAbs{
        l_r\bigRound{
            F_\vecbf{A}(x_i)_y - \max_{k\ne y} F_\vecbf{A}(x_i)_k
        } - 
        l_r\bigRound{
            F_\vecbf{\bar A}(x_i)_y - \max_{k\ne y} F_\vecbf{\bar A}(x_i)_k
        }
    } \\
    &\le \frac{1}{r} \bigAbs{
        \bigRound{F_\vecbf{A}(x_i)_y - F_\vecbf{\bar A}(x_i)_y} +
        \bigRound{
            \max_{k\ne y} F_\vecbf{\bar A}(x_i)_k - \max_{k\ne y} F_\vecbf{A}(x_i)_k
        }
    } \ \ \ \text{($l_r$ is $1/r$-Lipchitz)} \\
    &\le \frac{1}{r} \bigAbs{
        F_\vecbf{A}(x_i)_y - F_\vecbf{\bar A}(x_i)_y
    } + \frac{1}{r}\max_{k\ne y}\bigAbs{
        F_\vecbf{\bar A}(x_i)_k - F_\vecbf{A}(x_i)_k
    } \\
    &\le \frac{2}{r}\max_{j\in\{1, \dots, K\}} \bigAbs{F_\vecbf{A}(x_i)_j - F_\vecbf{\bar A}(x_i)_j} \\
    &= \frac{2}{r}\max_{j\in\{1, \dots, K\}} \bigAbs{
        A^{(2)}_j\sigma\bigRound{A^{(1)}x_i} - \bar A^{(2)}_j\sigma\bigRound{\bar A^{(1)}x_i}
    } \\
    &= \frac{2}{r}\max_{j\in\{1, \dots, K\}} \bigAbs{
        A_j^{(2)}\bigRound{\sigma\bigRound{A^{(1)}x_i} - \sigma\bigRound{\bar A^{(1)}x_i}}
        + \bigRound{A_j^{(2)} - \bar A_j^{(2)}}\sigma\bigRound{\bar A^{(1)}x_i} 
    } \\
    &\le \frac{2}{r}\max_{j\in\{1, \dots, K\}}\bigAbs{
        A_j^{(2)}\bigRound{\sigma\bigRound{A^{(1)}x_i} - \sigma\bigRound{\bar A^{(1)}x_i}}
    } + \frac{2}{r}\max_{j\in\{1, \dots, K\}}\bigAbs{
        \bigRound{A_j^{(2)} - \bar A_j^{(2)}}\sigma\bigRound{\bar A^{(1)}x_i} 
    } \\
    &= \frac{2}{r}\Big\| 
        A^{(2)}\bigRound{\sigma\bigRound{A^{(1)}x_i} - \sigma\bigRound{\bar A^{(1)}x_i}}
    \Big\|_\infty + 
    \frac{2}{r}\Big\|
        \bigRound{A^{(2)} - \bar A^{(2)}}\sigma\bigRound{\bar A^{(1)}x_i} 
    \Big\|_\infty \\
    &\le \frac{2}{r} \|A^{(2)}\|_{2,\infty} \Big\| \sigma\bigRound{A^{(1)}x_i} - \sigma\bigRound{\bar A^{(1)}x_i} \Big\|_2  + \frac{2}{r} \Big\| \bigRound{A^{(2)} - \bar A^{(2)}}\sigma\bigRound{\bar A^{(1)}x_i} \Big\|_\infty \\
    &\le \frac{2a_*}{r} \Big\| \sigma\bigRound{A^{(1)}x_i - \bar A^{(1)}x_i}\Big\|_2 + \frac{2}{r} \Big\| \bigRound{A^{(2)} - \bar A^{(2)}}\sigma\bigRound{\bar A^{(1)}x_i} \Big\|_\infty \\
    &\le \frac{2a_*\rho}{r} \Big\| A^{(1)}x_i - \bar A^{(1)}x_i \Big\|_2 + \frac{2}{r} \Big\| \bigRound{A^{(2)} - \bar A^{(2)}}\sigma\bigRound{\bar A^{(1)}x_i} \Big\|_\infty \\
\end{align*}

\noindent Now we define the following function classes
\begin{align*}
    \G_1 &= \bigCurl{
        x \mapsto A^{(1)}x : \|A^{(1)}\|_\sigma \le s_1, \|(A^{(1)} - M^{(1)})^T\|_{2, 1} \le a_1
    } \\
    \G_2 &= \bigCurl{
        z \mapsto A^{(2)}z : \|A^{(2)}\|_\sigma \le s_2, \|A^{(2)} - M^{(2)}\|_F \le a_*
    }
\end{align*}

\noindent We will proceed to cover $\mathcal{L}_r$ through covering $\G_1, \G_2$ with the following strategy:
\begin{itemize}
    \item Derive the covering number with granularity $\epsilon_1 > 0$ for $\G_1$ with respect to the $\|.\|_2^S$ norm over the original sample dataset $S$. Denote the desired cover as $\mathcal{C}$.
\end{itemize}
